{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Data Cleaning\n",
    "\n",
    "This notebook contains code which reads in area/route information gathered during the scraping process\n",
    "and cleans/processes it so it can analyzed and input into the recommender system algorithm.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import ast\n",
    "import pickle\n",
    "import warnings\n",
    "\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import functools\n",
    "import operator\n",
    "import os\n",
    "from MPAreaTree import MPAreaTree\n",
    "pd.set_option('display.max_colwidth', 4000)\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read in the boulder and trad/sport climb grades\n",
    "boulder_grades = pd.read_csv('./data/boulder_grades.csv')\n",
    "climb_grades = pd.read_csv('./data/climb_grades.csv')\n",
    "\n",
    "\n",
    "# Create a dictionary of the grades\n",
    "# adding an ordinal component so we can sort routes by difficulty \n",
    "grade_dict = {v:k for k,v in boulder_grades.to_dict()['grade'].items()}\n",
    "grade_dict.update({v:k for k,v in climb_grades.to_dict()['grade'].items()})\n",
    "\n",
    "\n",
    "# Clean and format the route descriptions, IDs, names, height, containing area, rating etc. \n",
    "def clean_routes(routes, drop_unrated = True):\n",
    "    cleaned_routes = routes.drop_duplicates()\n",
    "    \n",
    "    if drop_unrated:\n",
    "        cleaned_routes = cleaned_routes[~cleaned_routes.star_ratings.isnull()]\n",
    "        cleaned_routes = cleaned_routes[cleaned_routes['star_ratings'] != '{}']\n",
    "        \n",
    "    cleaned_routes['description'] = cleaned_routes['description'].fillna('')\n",
    "    cleaned_routes['id'] = cleaned_routes['id'].astype(int)\n",
    "    cleaned_routes = cleaned_routes.rename(columns = {'id' : 'route_id', 'name' : 'route_name'})\n",
    "    cleaned_routes['area_id'] = cleaned_routes['area_id'].astype(int)\n",
    "    cleaned_routes['pitches'] = cleaned_routes['pitches'].astype(int)\n",
    "    cleaned_routes['votes'] = cleaned_routes['votes'].astype(int)\n",
    "    cleaned_routes['route_name'] = cleaned_routes['route_name'].fillna('Unnamed')\n",
    "    cleaned_routes['height'] = cleaned_routes['height'].map(lambda x: 'Unspecified' if x == 0 else x)\n",
    "    # dictionary of user ratings is saved as a string, convert to a python dict\n",
    "    cleaned_routes['star_ratings'] = cleaned_routes['star_ratings'].map(lambda x: ast.literal_eval(x))\n",
    "       \n",
    "    \n",
    "    # remove ungraded routes for now\n",
    "    cleaned_routes = cleaned_routes[~cleaned_routes['grade'].isin(['5.?', 'V?', ''])]\n",
    "    cleaned_routes = cleaned_routes[cleaned_routes['grade'].isin(grade_dict.keys())]\n",
    "    \n",
    "    cleaned_routes = cleaned_routes[cleaned_routes['pitches'] != 80]\n",
    "    cleaned_routes['grade_numeric'] = cleaned_routes['grade'].map(grade_dict).astype(int)\n",
    "    return cleaned_routes\n",
    "\n",
    "# Clean an areas information\n",
    "def clean_area(areas):\n",
    "    cleaned_areas = areas.drop_duplicates()\n",
    "    \n",
    "    cleaned_areas['parent_id'] = cleaned_areas['parent_id'].fillna(0)\n",
    "    cleaned_areas['parent_id'] = cleaned_areas['parent_id'].astype(int)\n",
    "    cleaned_areas = cleaned_areas.rename(columns = {'id' : 'area_id', 'name' : 'area_name'})\n",
    "    return cleaned_areas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# traverse the rating dictionary for a dataframe of routes\n",
    "# extract the user/route IDs and corresponding rating\n",
    "# this generates the main user/route rating matrix used in the recommender system algorithm\n",
    "def get_ratings(routes):\n",
    "    ratings = []\n",
    "    for i,row in routes.iterrows():\n",
    "        for user, stars in row['star_ratings'].items():\n",
    "            ratings.append({'user_id': user, 'route_id' : row['route_id'], 'user_rating' : stars})\n",
    "\n",
    "    ratings = pd.DataFrame(ratings)\n",
    "    \n",
    "    return pd.merge(ratings, routes, left_on = 'route_id', right_on='route_id').drop(columns = 'star_ratings')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load in each states area/route information collected in step 1 of the scraping process\n",
    "def load_state_routes_areas(states):\n",
    "    routes = []\n",
    "    areas = []\n",
    "    for state in states:\n",
    "        if os.path.exists(f'./data/{state}_routes.csv') and os.path.exists(f'./data/{state}_areas.csv'):\n",
    "            print(f'Found route/area data for {state}.')\n",
    "            r = clean_routes(pd.read_csv(f'./data/{state}_routes.csv',quoting=2, error_bad_lines=False))        \n",
    "            a = clean_area(pd.read_csv(f'./data/{state}_areas.csv'))\n",
    "\n",
    "            r['state'] = state\n",
    "            a['state'] = state\n",
    "            r = r.merge(a[['area_id', 'area_name']], left_on = 'area_id', right_on = 'area_id')\n",
    "            routes.append(r)\n",
    "            areas.append(a)            \n",
    "    \n",
    "    routes = pd.concat(routes).reset_index(drop = True)\n",
    "    areas = pd.concat(areas).reset_index(drop = True)\n",
    "    print(f'Loaded route/area data for {areas[\"state\"].unique().shape[0]} states.')\n",
    "    print(f\"Found {routes['route_id'].unique().shape[0]} unique routes in {areas['area_id'].unique().shape[0]} unique areas.\")\n",
    "    return routes, areas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found route/area data for Alaska.\n",
      "Found route/area data for Alabama.\n",
      "Found route/area data for Arkansas.\n",
      "Found route/area data for Arizona.\n",
      "Found route/area data for California.\n",
      "Found route/area data for Colorado.\n",
      "Found route/area data for Connecticut.\n",
      "Found route/area data for Delaware.\n",
      "Found route/area data for Florida.\n",
      "Found route/area data for Georgia.\n",
      "Found route/area data for Hawaii.\n",
      "Found route/area data for Iowa.\n",
      "Found route/area data for Idaho.\n",
      "Found route/area data for Illinois.\n",
      "Found route/area data for Indiana.\n",
      "Found route/area data for Kansas.\n",
      "Found route/area data for Kentucky.\n",
      "Found route/area data for Louisiana.\n",
      "Found route/area data for Massachusetts.\n",
      "Found route/area data for Maryland.\n",
      "Found route/area data for Maine.\n",
      "Found route/area data for Michigan.\n",
      "Found route/area data for Minnesota.\n",
      "Found route/area data for Missouri.\n",
      "Found route/area data for Mississippi.\n",
      "Found route/area data for Montana.\n",
      "Found route/area data for North Carolina.\n",
      "Found route/area data for North Dakota.\n",
      "Found route/area data for Nebraska.\n",
      "Found route/area data for New Hampshire.\n",
      "Found route/area data for New Jersey.\n",
      "Found route/area data for New Mexico.\n",
      "Found route/area data for Nevada.\n",
      "Found route/area data for New York.\n",
      "Found route/area data for Ohio.\n",
      "Found route/area data for Oklahoma.\n",
      "Found route/area data for Oregon.\n",
      "Found route/area data for Pennsylvania.\n",
      "Found route/area data for Rhode Island.\n",
      "Found route/area data for South Carolina.\n",
      "Found route/area data for South Dakota.\n",
      "Found route/area data for Tennessee.\n",
      "Found route/area data for Texas.\n",
      "Found route/area data for Utah.\n",
      "Found route/area data for Virginia.\n",
      "Found route/area data for Vermont.\n",
      "Found route/area data for Washington.\n",
      "Found route/area data for Wisconsin.\n",
      "Found route/area data for West Virginia.\n",
      "Found route/area data for Wyoming.\n",
      "Loaded route/area data for 50 states.\n",
      "Found 164799 unique routes in 43299 unique areas.\n"
     ]
    }
   ],
   "source": [
    "state_names = [\"Alaska\", \"Alabama\", \"Arkansas\", \"Arizona\", \"California\", \"Colorado\", \"Connecticut\", \n",
    "               \"Delaware\", \"Florida\", \"Georgia\",  \"Hawaii\", \"Iowa\", \"Idaho\", \"Illinois\", \"Indiana\", \"Kansas\",\n",
    "               \"Kentucky\", \"Louisiana\", \"Massachusetts\", \"Maryland\", \"Maine\", \"Michigan\", \"Minnesota\", \"Missouri\", \n",
    "               \"Mississippi\", \"Montana\", \"North Carolina\",  \"North Dakota\", \"Nebraska\", \"New Hampshire\", \n",
    "               \"New Jersey\", \"New Mexico\", \"Nevada\", \"New York\", \"Ohio\", \"Oklahoma\", \"Oregon\", \n",
    "               \"Pennsylvania\", \"Rhode Island\", \"South Carolina\", \"South Dakota\", \n",
    "               \"Tennessee\", \"Texas\", \"Utah\", \"Virginia\",  \"Vermont\", \n",
    "               \"Washington\", \"Wisconsin\", \"West Virginia\", \"Wyoming\"]\n",
    "routes, areas = load_state_routes_areas(state_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate the MPAreaTree (see associated python file) and the rating/route matrix\n",
    "area_tree = MPAreaTree(areas)\n",
    "ratings = get_ratings(routes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2166284, 15)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ratings.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save all cleaned dataframes\n",
    "routes.to_csv('./data/routes.csv', index = False)\n",
    "areas.to_csv('./data/areas.csv', index = False)\n",
    "ratings.to_csv('./data/ratings.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pickle the area tree object for use in the streamlight demo\n",
    "pickle.dump(area_tree, open('./pickle/area_tree.pkl', 'wb'))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
